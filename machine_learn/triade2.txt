Awesome! You're about to learn a very powerful concept in machine learning: the **`Pipeline`**.

Think of a pipeline like a **recipe** that:

1. **Preprocesses your data** (scale numbers, vectorize text)
2. **Feeds it into a model**
3. Keeps everything neat and repeatable

---

## ‚úÖ Complete Working Script (Start to Finish)

This script:

* Loads the `health_data.csv` file
* Prepares the numeric and text data
* Builds a pipeline with preprocessing and a classifier
* Trains the model
* Evaluates it

---

### üìú `predict_health.py`

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report

# Step 1: Load the CSV data
df = pd.read_csv("health_data.csv")

# Step 2: Clean missing values (optional: you can do more advanced handling later)
df.fillna(0, inplace=True)  # replaces empty strings, NaNs with 0

# Step 3: Define features and labels
X = df[['heart_rate', 'bp_sys', 'bp_dia', 'temperature', 'weight', 'symptoms']]
y = df['severity']  # target: red, green, amber, yellow

# Step 4: Define which columns are numeric and which are text
numeric_features = ['heart_rate', 'bp_sys', 'bp_dia', 'temperature', 'weight']
text_feature = 'symptoms'

# Step 5: Create column transformer
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_features),
    ('text', TfidfVectorizer(), text_feature)
])

# Step 6: Create the pipeline
pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Step 7: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 8: Train the model
pipeline.fit(X_train, y_train)

# Step 9: Evaluate the model
y_pred = pipeline.predict(X_test)
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Optional: Predict new data
new_data = pd.DataFrame([{
    'heart_rate': 140,
    'bp_sys': 160,
    'bp_dia': 100,
    'temperature': 40.2,
    'weight': 85,
    'symptoms': 'severe headache and chest pain'
}])
prediction = pipeline.predict(new_data)
print(f"\nPrediction for new patient: {prediction[0].upper()}")
```

---

## üîß What You Need to Do

1. **Create** `health_data.csv` (from earlier)
2. **Save** this Python code as `predict_health.py`
3. **Run** in terminal:

```bash
python predict_health.py
```

---

## üîç How the Pipeline Works

```text
[ heart_rate, bp_sys, ... symptoms ] ‚Üí preprocess (scale + text vector) ‚Üí model
```

* `StandardScaler()` scales the numbers
* `TfidfVectorizer()` converts the symptom text to numbers
* `RandomForestClassifier()` learns from the processed data

---

Would you like me to help you turn this into a basic web app later?
